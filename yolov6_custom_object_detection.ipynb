{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samin-Sadaf7/ObjectDetectiongwithYolo/blob/main/yolov6_custom_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6QhTPHOHdQP",
        "outputId": "e822dd64-51af-4490-a4b8-08052b919635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'YOLOv6' already exists and is not an empty directory.\n",
            "/content/YOLOv6\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.18.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.10.0.84)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.5)\n",
            "Collecting addict>=2.4.0 (from -r requirements.txt (line 11))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.17.0)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.0.8)\n",
            "Collecting onnx>=1.10.0 (from -r requirements.txt (line 14))\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnx-simplifier>=0.3.6 (from -r requirements.txt (line 15))\n",
            "  Downloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting thop (from -r requirements.txt (line 16))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 4))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.0.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (13.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: addict, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, onnx-simplifier, nvidia-cusolver-cu12, thop\n",
            "Successfully installed addict-2.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 onnx-1.16.2 onnx-simplifier-0.4.36 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# Download MT-YOLOv6 repository and install requirements\n",
        "!git clone https://github.com/meituan/YOLOv6\n",
        "%cd YOLOv6\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSkAM3X0HpCd",
        "outputId": "c359312d-14c4-43be-b948-5dfdcaeb2644"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define the data\n",
        "data = {\n",
        "    'nc': 15,\n",
        "    'train': '/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/train',\n",
        "    'val': '/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/test',\n",
        "    'names': [\n",
        "        'SpeedLimit60kmh',\n",
        "        'School',\n",
        "        'PEDESTRIANCROSSING',\n",
        "        'SharpBendToTheLeft',\n",
        "        'U Turn',\n",
        "        'speedlimit80kmh',\n",
        "        'NoOvertaking',\n",
        "        'SharpBendToTheRight',\n",
        "        'SideRoadLeft',\n",
        "        'SideRoadRight',\n",
        "        'speedlimit40kmh',\n",
        "        'NarrowBridge',\n",
        "        'RoadHump',\n",
        "        'nouseofhorn',\n",
        "        'Crossroads'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Write the data to conference.yml\n",
        "with open('conference.yml', 'w') as yaml_file:\n",
        "    yaml.dump(data, yaml_file)"
      ],
      "metadata": {
        "id": "Bs6v401K0OVr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --batch 256 --conf configs/yolov6s_finetune.py --data /content/YOLOv6/conference.yml --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxs523CI3io",
        "outputId": "fbbdb0cd-bd17-4df9-d45d-f31585528e91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-10 17:13:25.738317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-10 17:13:25.773180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-10 17:13:25.785308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-10 17:13:25.810451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-10 17:13:26.903102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using 1 GPU for training... \n",
            "training args are: Namespace(data_path='/content/YOLOv6/conference.yml', conf_file='configs/yolov6s_finetune.py', img_size=640, rect=False, batch_size=256, epochs=400, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=False, distill_feat=False, quant=False, calib=False, teacher_model_path=None, temperature=20, fuse_ab=False, bs_per_gpu=32, specific_shape=False, height=None, width=None, cache_ram=False, rank=-1, world_size=1, save_dir='runs/train/exp4')\n",
            "\n",
            "Loading state_dict from weights/yolov6s.pt for fine-tuning...\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cspsppf): CSPSPPFModule(\n",
            "          (cv1): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv2): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv3): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv4): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "          (cv5): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv6): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv7): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepBiFPANNeck(\n",
            "    (reduce_layer0): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion0): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion1): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample2): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.train_cache.json\n",
            "Train: Final numbers of valid images: 95/ labels: 95. \n",
            "0.1s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.test_cache.json\n",
            "Val: Checking formats of images with 2 process(es): \n",
            "0 image(s) corrupted: 100% 4/4 [00:01<00:00,  2.26it/s]\n",
            "Val: Checking formats of labels with 2 process(es): \n",
            "0 label(s) found, 4 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 4/4 [00:00<00:00, 326.37it/s]\n",
            "WARNING: No labels found in /content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/test/images. \n",
            "Convert to COCO format\n",
            "100% 4/4 [00:00<00:00, 43804.74it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Dataset- -Conference/annotations/instances_test.json\n",
            "Val: Final numbers of valid images: 4/ labels: 4. \n",
            "2.2s for dataset initialization.\n",
            "Training start...\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "  0%|          | 0/1 [00:45<?, ?it/s]                                                               \n",
            "ERROR in training steps.\n",
            "ERROR in training loop or eval/save model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/YOLOv6/tools/train.py\", line 143, in <module>\n",
            "    main(args)\n",
            "  File \"/content/YOLOv6/tools/train.py\", line 133, in main\n",
            "    trainer.train()\n",
            "  File \"/content/YOLOv6/yolov6/core/engine.py\", line 121, in train\n",
            "    self.train_one_epoch(self.epoch)\n",
            "  File \"/content/YOLOv6/yolov6/core/engine.py\", line 135, in train_one_epoch\n",
            "    self.train_in_steps(epoch_num, self.step)\n",
            "  File \"/content/YOLOv6/yolov6/core/engine.py\", line 152, in train_in_steps\n",
            "    preds, s_featmaps = self.model(images)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/models/yolo.py\", line 40, in forward\n",
            "    x = self.detect(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/models/effidehead.py\", line 80, in forward\n",
            "    cls_feat = self.cls_convs[i](cls_x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/layers/common.py\", line 74, in forward\n",
            "    return self.block(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/layers/common.py\", line 49, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\", line 396, in forward\n",
            "    return F.silu(input, inplace=self.inplace)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2101, in silu\n",
            "    return torch._C._nn.silu_(input)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 76.00 MiB. GPU \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --batch 32 --conf configs/yolov6s.py --epochs 100  --data /content/YOLOv6/conference.yml --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGySaXepIDia",
        "outputId": "e34e3319-6c4b-4535-d674-3c6e11308458"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-10 17:14:24.575698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-10 17:14:24.596707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-10 17:14:24.603502: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-10 17:14:24.619705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-10 17:14:25.786769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using 1 GPU for training... \n",
            "training args are: Namespace(data_path='/content/YOLOv6/conference.yml', conf_file='configs/yolov6s.py', img_size=640, rect=False, batch_size=32, epochs=100, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=False, distill_feat=False, quant=False, calib=False, teacher_model_path=None, temperature=20, fuse_ab=False, bs_per_gpu=32, specific_shape=False, height=None, width=None, cache_ram=False, rank=-1, world_size=1, save_dir='runs/train/exp5')\n",
            "\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cspsppf): CSPSPPFModule(\n",
            "          (cv1): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv2): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv3): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv4): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "          (cv5): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv6): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv7): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepBiFPANNeck(\n",
            "    (reduce_layer0): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion0): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion1): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample2): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.train_cache.json\n",
            "Train: Final numbers of valid images: 95/ labels: 95. \n",
            "0.1s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.test_cache.json\n",
            "Convert to COCO format\n",
            "100% 4/4 [00:00<00:00, 36792.14it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Dataset- -Conference/annotations/instances_test.json\n",
            "Val: Final numbers of valid images: 4/ labels: 4. \n",
            "0.1s for dataset initialization.\n",
            "Training start...\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      0/99       0.01     1.331         0     2.098: 100%|██████████| 3/3 [00:25<00:00,  8.34s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      1/99       0.01     1.399         0     1.963: 100%|██████████| 3/3 [00:12<00:00,  4.16s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      2/99   0.009998     1.354         0     2.045: 100%|██████████| 3/3 [00:19<00:00,  6.33s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      3/99    0.00999     1.352         0     2.062: 100%|██████████| 3/3 [00:11<00:00,  3.73s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      4/99   0.009978     1.406         0     1.906: 100%|██████████| 3/3 [00:19<00:00,  6.62s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      5/99   0.009961     1.332         0     2.025: 100%|██████████| 3/3 [00:11<00:00,  3.68s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      6/99   0.009939     1.329         0     2.041: 100%|██████████| 3/3 [00:19<00:00,  6.50s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      7/99   0.009912     1.291         0     2.089: 100%|██████████| 3/3 [00:10<00:00,  3.40s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      8/99   0.009881     1.389         0     1.917: 100%|██████████| 3/3 [00:18<00:00,  6.23s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      9/99   0.009844     1.383         0     1.937: 100%|██████████| 3/3 [00:08<00:00,  2.95s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     10/99   0.009803     1.366         0     1.961: 100%|██████████| 3/3 [00:19<00:00,  6.34s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     11/99   0.009758     1.339         0     2.009: 100%|██████████| 3/3 [00:08<00:00,  2.82s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     12/99   0.009707     1.375         0     1.927: 100%|██████████| 3/3 [00:19<00:00,  6.49s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     13/99   0.009652     1.371         0     1.902: 100%|██████████| 3/3 [00:08<00:00,  2.97s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     14/99   0.009593     1.371         0     1.898: 100%|██████████| 3/3 [00:18<00:00,  6.27s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     15/99   0.009529     1.381         0      1.88: 100%|██████████| 3/3 [00:11<00:00,  3.74s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     16/99    0.00946     1.352         0     1.915: 100%|██████████| 3/3 [00:18<00:00,  6.21s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     17/99   0.009388      1.34         0     1.952: 100%|██████████| 3/3 [00:11<00:00,  3.78s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     18/99   0.009311     1.333         0     1.955: 100%|██████████| 3/3 [00:18<00:00,  6.16s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     19/99   0.009229     1.375         0     1.863: 100%|██████████| 3/3 [00:11<00:00,  3.99s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Epoch: 19 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     20/99   0.009144     1.345         0     1.914: 100%|██████████| 3/3 [00:13<00:00,  4.54s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     21/99   0.009055     1.377         0     1.935: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     22/99   0.008961     1.353         0     1.882: 100%|██████████| 3/3 [00:15<00:00,  5.31s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     23/99   0.008864     1.369         0     1.815: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     24/99   0.008763     1.383         0     1.841: 100%|██████████| 3/3 [00:15<00:00,  5.01s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     25/99   0.008658     1.312         0     1.943: 100%|██████████| 3/3 [00:06<00:00,  2.06s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     26/99    0.00855     1.361         0     1.884: 100%|██████████| 3/3 [00:16<00:00,  5.50s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     27/99   0.008439     1.336         0     1.905: 100%|██████████| 3/3 [00:07<00:00,  2.47s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     28/99   0.008323     1.345         0     1.857: 100%|██████████| 3/3 [00:16<00:00,  5.48s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     29/99   0.008205     1.391         0     1.791: 100%|██████████| 3/3 [00:08<00:00,  2.76s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     30/99   0.008084     1.355         0      1.89: 100%|██████████| 3/3 [00:16<00:00,  5.44s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     31/99    0.00796     1.366         0      1.87: 100%|██████████| 3/3 [00:08<00:00,  2.68s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     32/99   0.007832      1.34         0     1.886: 100%|██████████| 3/3 [00:15<00:00,  5.24s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     33/99   0.007702      1.35         0     1.877: 100%|██████████| 3/3 [00:05<00:00,  1.74s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     34/99    0.00757     1.352         0      1.87: 100%|██████████| 3/3 [00:15<00:00,  5.08s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     35/99   0.007435     1.321         0      1.96: 100%|██████████| 3/3 [00:06<00:00,  2.01s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     36/99   0.007297     1.414         0     1.816: 100%|██████████| 3/3 [00:15<00:00,  5.22s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     37/99   0.007158     1.308         0     1.906: 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     38/99   0.007016     1.272         0     2.028: 100%|██████████| 3/3 [00:16<00:00,  5.38s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     39/99   0.006872     1.387         0     1.817: 100%|██████████| 3/3 [00:08<00:00,  2.68s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00, 18.20it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Epoch: 39 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     40/99   0.006727     1.312         0     1.986: 100%|██████████| 3/3 [00:16<00:00,  5.34s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     41/99    0.00658     1.326         0     1.873: 100%|██████████| 3/3 [00:08<00:00,  2.98s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     42/99   0.006431     1.307         0     1.941: 100%|██████████| 3/3 [00:16<00:00,  5.38s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     43/99   0.006281      1.32         0     1.932: 100%|██████████| 3/3 [00:06<00:00,  2.20s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     44/99    0.00613     1.314         0     1.854: 100%|██████████| 3/3 [00:15<00:00,  5.10s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     45/99   0.005978     1.318         0     1.846: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     46/99   0.005824     1.259         0     1.904: 100%|██████████| 3/3 [00:14<00:00,  4.97s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     47/99    0.00567     1.244         0     1.924: 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     48/99   0.005516     1.363         0     1.901: 100%|██████████| 3/3 [00:17<00:00,  5.68s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     49/99   0.005361     1.334         0     1.846: 100%|██████████| 3/3 [00:07<00:00,  2.45s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     50/99   0.005205     1.249         0     1.937: 100%|██████████| 3/3 [00:16<00:00,  5.39s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00, 15.99it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Epoch: 50 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     51/99    0.00505     1.352         0      1.86: 100%|██████████| 3/3 [00:08<00:00,  2.85s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     52/99   0.004895      1.29         0      1.87: 100%|██████████| 3/3 [00:16<00:00,  5.37s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     53/99   0.004739     1.327         0     1.809: 100%|██████████| 3/3 [00:06<00:00,  2.32s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00, 10.68it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 53 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     54/99   0.004584     1.275         0     1.887: 100%|██████████| 3/3 [00:13<00:00,  4.65s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     55/99    0.00443      1.25         0     1.845: 100%|██████████| 3/3 [00:06<00:00,  2.22s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     56/99   0.004276     1.292         0     1.793: 100%|██████████| 3/3 [00:14<00:00,  4.94s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 56 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     57/99   0.004122      1.28         0     1.731: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     58/99    0.00397     1.228         0     1.799: 100%|██████████| 3/3 [00:16<00:00,  5.39s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     59/99   0.003819      1.22         0     1.774: 100%|██████████| 3/3 [00:06<00:00,  2.32s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  6.12it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 59 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     60/99   0.003669      1.19         0     1.709: 100%|██████████| 3/3 [00:15<00:00,  5.30s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     61/99    0.00352     1.195         0      1.69: 100%|██████████| 3/3 [00:09<00:00,  3.11s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     62/99   0.003373     1.183         0     1.731: 100%|██████████| 3/3 [00:16<00:00,  5.40s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 62 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     63/99   0.003228     1.195         0     1.822: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     64/99   0.003084     1.212         0     1.682: 100%|██████████| 3/3 [00:16<00:00,  5.40s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     65/99   0.002942      1.23         0      1.66: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00, 11.94it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 65 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     66/99   0.002803     1.221         0     1.725: 100%|██████████| 3/3 [00:14<00:00,  4.89s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     67/99   0.002665     1.129         0     1.664: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     68/99    0.00253      1.23         0     1.652: 100%|██████████| 3/3 [00:12<00:00,  4.05s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 68 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     69/99   0.002398      1.15         0     1.654: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     70/99   0.002268     1.155         0      1.62: 100%|██████████| 3/3 [00:13<00:00,  4.57s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     71/99    0.00214     1.178         0     1.722: 100%|██████████| 3/3 [00:09<00:00,  3.15s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.43it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 71 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     72/99   0.002016     1.124         0     1.699: 100%|██████████| 3/3 [00:14<00:00,  4.74s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     73/99   0.001895     1.175         0     1.704: 100%|██████████| 3/3 [00:11<00:00,  3.75s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     74/99   0.001777     1.103         0     1.661: 100%|██████████| 3/3 [00:15<00:00,  5.02s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 74 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     75/99   0.001661      1.14         0     1.721: 100%|██████████| 3/3 [00:07<00:00,  2.50s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     76/99    0.00155     1.109         0     1.682: 100%|██████████| 3/3 [00:13<00:00,  4.62s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     77/99   0.001442     1.098         0      1.66: 100%|██████████| 3/3 [00:08<00:00,  2.67s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.03s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 77 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     78/99   0.001337     1.123         0      1.62: 100%|██████████| 3/3 [00:12<00:00,  4.12s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     79/99   0.001236     1.123         0      1.62: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     80/99   0.001139      1.12         0     1.592: 100%|██████████| 3/3 [00:13<00:00,  4.63s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 80 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     81/99   0.001045     1.102         0     1.694: 100%|██████████| 3/3 [00:08<00:00,  2.68s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     82/99   0.000956     1.079         0     1.728: 100%|██████████| 3/3 [00:15<00:00,  5.00s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     83/99  0.0008706     1.015         0     1.646: 100%|██████████| 3/3 [00:10<00:00,  3.51s/it]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.12it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.51s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 83 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     84/99  0.0007893     1.117         0     1.598: 100%|██████████| 3/3 [00:13<00:00,  4.49s/it]  \n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.train_cache.json\n",
            "Train: Final numbers of valid images: 95/ labels: 95. \n",
            "0.2s for dataset initialization.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "img record infomation path is:/content/drive/MyDrive/Dataset- -Conference/Dataset- -Conference/.test_cache.json\n",
            "Convert to COCO format\n",
            "100% 4/4 [00:00<00:00, 35394.97it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Dataset- -Conference/annotations/instances_test.json\n",
            "Val: Final numbers of valid images: 4/ labels: 4. \n",
            "0.1s for dataset initialization.\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     85/99  0.0007123     1.057         0     1.705: 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     86/99  0.0006395     1.019         0     1.707: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.33it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 86 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     87/99  0.0005711     1.046         0     1.644: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     88/99  0.0005071     1.055         0     1.623: 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     89/99  0.0004476     1.009         0     1.673: 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  3.46it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 89 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     90/99  0.0003926     1.018         0      1.64: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     91/99  0.0003423     1.102         0       1.6: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     92/99  0.0002965     1.016         0     1.538: 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.86it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 92 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     93/99  0.0002555     1.017         0     1.638: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     94/99  0.0002192     1.038         0     1.559: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     95/99  0.0001877      1.02         0     1.547: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.52s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 95 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     96/99  0.0001609     1.039         0     1.574: 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     97/99   0.000139     1.075         0     1.568: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]  \n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     98/99   0.000122     1.112         0     1.598: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 98 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     99/99  0.0001098     1.012         0     1.655: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]  \n",
            "Inferencing model in train datasets.: 100%|███████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp5/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.03s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "Results saved to runs/train/exp5\n",
            "Epoch: 99 | mAP@0.5: -1.0 | mAP@0.50:0.95: -1.0\n",
            "\n",
            "Training completed in 0.490 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/eval.py --data /content/YOLOv6/conference.yml --img-size 416 --weights runs/train/exp/weights/best_ckpt.pt --device 0"
      ],
      "metadata": {
        "id": "cbf7d6KfI96J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad202dac-432d-4f73-853c-e0722fccb0cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data='/content/YOLOv6/conference.yml', weights='runs/train/exp/weights/best_ckpt.pt', batch_size=32, img_size=416, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='exp', shrink_size=0, infer_on_rect=True, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=False, plot_curve=True, plot_confusion_matrix=False, verbose=False, config_file='', specific_shape=False, height=None, width=None)\n",
            "checkpoint best_ckpt.pt not exist, try to downloaded it from github.\n",
            "downloading url is: https://github.com/meituan/YOLOv6/releases/download/0.4.0/best_ckpt.pt, pealse make sure the version of the downloading model is correspoing to the code version!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/YOLOv6/tools/eval.py\", line 168, in <module>\n",
            "    main(args)\n",
            "  File \"/content/YOLOv6/tools/eval.py\", line 163, in main\n",
            "    run(**vars(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/YOLOv6/tools/eval.py\", line 152, in run\n",
            "    model = val.init_model(model, weights, task)\n",
            "  File \"/content/YOLOv6/yolov6/core/evaler.py\", line 66, in init_model\n",
            "    download_ckpt(weights)\n",
            "  File \"/content/YOLOv6/yolov6/utils/general.py\", line 99, in download_ckpt\n",
            "    assert r.status_code == 200, \"Unable to download checkpoints, manually download it\"\n",
            "AssertionError: Unable to download checkpoints, manually download it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/infer.py --yaml /content/YOLOv6/conference.yml --img-size 416 --weights runs/train/exp/weights/best_ckpt.pt --source {just_test_location_tar path_eikhane_paste hobe} --device 0"
      ],
      "metadata": {
        "id": "FCwD9_Oqz6MW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1dc570f-7a05-48cd-bd29-73cb1672e41c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: infer.py [-h] [--weights WEIGHTS] [--source SOURCE] [--webcam] [--webcam-addr WEBCAM_ADDR]\n",
            "                [--yaml YAML] [--img-size IMG_SIZE [IMG_SIZE ...]] [--conf-thres CONF_THRES]\n",
            "                [--iou-thres IOU_THRES] [--max-det MAX_DET] [--device DEVICE] [--save-txt]\n",
            "                [--not-save-img] [--save-dir SAVE_DIR] [--view-img]\n",
            "                [--classes CLASSES [CLASSES ...]] [--agnostic-nms] [--project PROJECT]\n",
            "                [--name NAME] [--hide-labels] [--hide-conf] [--half]\n",
            "infer.py: error: unrecognized arguments: path_eikhane_paste hobe}\n"
          ]
        }
      ]
    }
  ]
}