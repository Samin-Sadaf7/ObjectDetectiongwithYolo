{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOkPHTt/CLOFL2Gsz5OxEPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samin-Sadaf7/ObjectDetectiongwithYolo/blob/main/Yolov8WithAttentionBlock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-tfdLzHtkKA",
        "outputId": "587bcfc4-502a-47c1-93d9-bf571ce5c894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 19 20:57:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbX5tZFDt7eU",
        "outputId": "96ecfb8c-df06-4e99-9055-3e53d9f2275c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT9bAigot9iv",
        "outputId": "3fc0f2f1-f3e8-4b5b-f763-812e5b0e65d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.2/235.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "yD4AVBSvuLxn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSGnih-guN0N",
        "outputId": "00e57d01-a5e4-41b1-b218-1c35b637c0ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 2, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels // 2, in_channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention = self.conv1(x)\n",
        "        attention = self.conv2(attention)\n",
        "        attention = self.sigmoid(attention)\n",
        "        return x * attention\n",
        "\n",
        "class YOLOv8WithAttention(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(YOLOv8WithAttention, self).__init__()\n",
        "        self.original_model = original_model\n",
        "        self.attention_block = AttentionBlock(in_channels=256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.original_model.backbone(x)\n",
        "        x = self.attention_block(x)\n",
        "        x = self.original_model.head(x)\n",
        "        return x\n",
        "\n",
        "# Load original YOLOv8 model\n",
        "original_model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Create new model with attention\n",
        "model_with_attention = YOLOv8WithAttention(original_model)"
      ],
      "metadata": {
        "id": "0ZUW_VxruATd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80769746-e9a6-48d8-9cbf-5650d39201fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 108MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade torch ultralytics"
      ],
      "metadata": {
        "id": "Zf0h1AskutXF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_attention.train=original_model.train"
      ],
      "metadata": {
        "id": "dUGhxTPQvdti"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_attention.training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brz0aRpcx3S2",
        "outputId": "70dbf86e-23bf-49eb-9777-e861d39e42ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TigmYiBKyxwI",
        "outputId": "990c2c16-6177-46d8-c267-811448b467a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLOv8WithAttention(\n",
              "  (original_model): YOLO(\n",
              "    (model): DetectionModel(\n",
              "      (model): Sequential(\n",
              "        (0): Conv(\n",
              "          (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv(\n",
              "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): Conv(\n",
              "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (4): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0-1): 2 x Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): Conv(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (6): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0-1): 2 x Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): Conv(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (8): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): SPPF(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (10): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (11): Concat()\n",
              "        (12): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (13): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (14): Concat()\n",
              "        (15): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (16): Conv(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (17): Concat()\n",
              "        (18): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (19): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (20): Concat()\n",
              "        (21): C2f(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): ModuleList(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (22): Detect(\n",
              "          (cv2): ModuleList(\n",
              "            (0): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (2): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (cv3): ModuleList(\n",
              "            (0): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (2): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (dfl): DFL(\n",
              "            (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (attention_block): AttentionBlock(\n",
              "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "results = model_with_attention.train(data='/content/drive/MyDrive/Dataset- -Conference/dataset.yaml',freeze=20, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogqAU8ZpuIHs",
        "outputId": "21498b82-f1c0-419d-d0e4-5c9a16f73925"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.77 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/Dataset- -Conference/dataset.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=20, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=15\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    754237  ultralytics.nn.modules.head.Detect           [15, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3013773 parameters, 3013757 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv1.conv.weight'\n",
            "Freezing layer 'model.12.cv1.bn.weight'\n",
            "Freezing layer 'model.12.cv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.bn.bias'\n",
            "Freezing layer 'model.12.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.12.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.12.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.12.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.12.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.12.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.15.cv1.conv.weight'\n",
            "Freezing layer 'model.15.cv1.bn.weight'\n",
            "Freezing layer 'model.15.cv1.bn.bias'\n",
            "Freezing layer 'model.15.cv2.conv.weight'\n",
            "Freezing layer 'model.15.cv2.bn.weight'\n",
            "Freezing layer 'model.15.cv2.bn.bias'\n",
            "Freezing layer 'model.15.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.15.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.15.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.15.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.15.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.15.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.16.conv.weight'\n",
            "Freezing layer 'model.16.bn.weight'\n",
            "Freezing layer 'model.16.bn.bias'\n",
            "Freezing layer 'model.18.cv1.conv.weight'\n",
            "Freezing layer 'model.18.cv1.bn.weight'\n",
            "Freezing layer 'model.18.cv1.bn.bias'\n",
            "Freezing layer 'model.18.cv2.conv.weight'\n",
            "Freezing layer 'model.18.cv2.bn.weight'\n",
            "Freezing layer 'model.18.cv2.bn.bias'\n",
            "Freezing layer 'model.18.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.18.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.18.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.18.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.18.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.18.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.19.conv.weight'\n",
            "Freezing layer 'model.19.bn.weight'\n",
            "Freezing layer 'model.19.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/utils/checks.py:558: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(True):\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py:238: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Dataset- -Conference/train/labels.cache... 2096 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2096/2096 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:805: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0)]  # transforms\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py:250: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Dataset- -Conference/valid/labels.cache... 256 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30     0.763G      1.539      5.893      1.097         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [12:13<00:00,  5.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:10<00:00,  1.34s/it]\n",
            "                   all        256        277      0.609     0.0672     0.0611     0.0409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30     0.763G       1.44      4.545      1.068         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.15it/s]\n",
            "                   all        256        277      0.294      0.274      0.178       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30     0.763G      1.445      3.902      1.062         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:32<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.02it/s]\n",
            "                   all        256        277      0.229      0.345      0.231      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30     0.761G       1.39      3.466      1.048         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
            "                   all        256        277      0.376      0.322      0.284      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30     0.763G       1.35      3.078      1.034         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:46<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
            "                   all        256        277      0.399      0.377      0.303      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30     0.761G      1.356      2.876       1.03         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:42<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.07s/it]\n",
            "                   all        256        277      0.425        0.4      0.346      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30     0.763G      1.332      2.638      1.035         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:38<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.29it/s]\n",
            "                   all        256        277      0.324      0.444      0.357      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30     0.761G      1.337      2.474      1.026         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.03s/it]\n",
            "                   all        256        277      0.318      0.427      0.356      0.233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30     0.763G      1.322       2.34      1.019         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:36<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
            "                   all        256        277      0.402      0.466      0.398      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30     0.761G      1.316      2.264      1.016         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:36<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.04it/s]\n",
            "                   all        256        277      0.527      0.357      0.417      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30     0.761G      1.294      2.139     0.9992         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.29it/s]\n",
            "                   all        256        277      0.444      0.437      0.434      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30     0.761G      1.295      2.123      1.011         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.12it/s]\n",
            "                   all        256        277      0.465      0.436      0.437      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30     0.763G       1.28      2.004      1.003         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:33<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.01s/it]\n",
            "                   all        256        277      0.487      0.436      0.448      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30     0.763G       1.28      1.968     0.9996         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.25it/s]\n",
            "                   all        256        277      0.481      0.427      0.452      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30     0.761G      1.266      1.934          1         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
            "                   all        256        277      0.501      0.418      0.458      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30     0.759G      1.262      1.877     0.9988         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.08it/s]\n",
            "                   all        256        277      0.584      0.426      0.476      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30     0.761G      1.248      1.834     0.9887         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.40it/s]\n",
            "                   all        256        277      0.571      0.425       0.48      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30     0.761G      1.249      1.799     0.9892         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.25it/s]\n",
            "                   all        256        277      0.533      0.433      0.495      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30     0.761G      1.223      1.768     0.9788         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:36<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.08it/s]\n",
            "                   all        256        277      0.572      0.433      0.501      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30     0.763G       1.23      1.736     0.9877         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:34<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.30it/s]\n",
            "                   all        256        277      0.528      0.465      0.508      0.335\n",
            "Closing dataloader mosaic\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:805: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0)]  # transforms\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py:250: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30     0.763G      1.237      1.869      1.008         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:36<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.13it/s]\n",
            "                   all        256        277      0.533      0.458      0.491      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30     0.763G      1.218      1.793     0.9929         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:32<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.03s/it]\n",
            "                   all        256        277      0.537      0.485      0.514      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30     0.765G      1.229      1.738     0.9988         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:33<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
            "                   all        256        277      0.557      0.462      0.505      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30     0.765G      1.219      1.741     0.9974         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:33<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
            "                   all        256        277      0.581      0.495      0.524      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30     0.765G      1.217      1.687     0.9913         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:33<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.21it/s]\n",
            "                   all        256        277       0.65      0.472      0.524      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30     0.765G      1.199       1.69     0.9879         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.08it/s]\n",
            "                   all        256        277      0.562      0.522      0.527       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30     0.765G      1.189      1.647     0.9946         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:31<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.02it/s]\n",
            "                   all        256        277      0.597      0.505      0.534      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30     0.765G      1.175       1.63     0.9816         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:37<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.32it/s]\n",
            "                   all        256        277      0.569      0.493      0.536      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30     0.765G      1.193      1.628     0.9863         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:35<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.11it/s]\n",
            "                   all        256        277      0.598      0.488       0.54      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30     0.763G       1.19      1.625      0.995         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [01:32<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.31it/s]\n",
            "                   all        256        277      0.634      0.483       0.54      0.343\n",
            "\n",
            "30 epochs completed in 1.042 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3008573 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:09<00:00,  1.17s/it]\n",
            "                   all        256        277      0.562      0.502      0.533      0.346\n",
            "   PEDESTRIAN CROSSING        256          9      0.607      0.778      0.747      0.464\n",
            "   speed limit 40 km/h        256         28      0.649      0.643      0.668       0.43\n",
            "   speed limit 80 km/h        256         26      0.591      0.334      0.466      0.296\n",
            "             Road Hump        256         19      0.833      0.474      0.606      0.378\n",
            "         No Overtaking        256         55       0.57      0.636       0.64      0.383\n",
            "        Side Road Left        256         26      0.666      0.731      0.744      0.506\n",
            "                School        256         28      0.772      0.714      0.774      0.512\n",
            "Sharp Bend To The Left        256         10      0.417        0.2      0.232      0.175\n",
            "       Side Road Right        256         15      0.471      0.667      0.723      0.478\n",
            "         Narrow Bridge        256         12          0          0      0.151     0.0939\n",
            "        no use of horn        256          8      0.368      0.375      0.415      0.327\n",
            "                U Turn        256         11      0.617       0.44      0.494      0.349\n",
            "            Crossroads        256         15      0.328      0.533      0.439      0.317\n",
            "   Speed Limit 60 km/h        256          6      0.537      0.776      0.619      0.354\n",
            "Sharp Bend To The Right        256          9          1      0.221      0.275      0.129\n",
            "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "iv8ik-8fQRTx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=val model='/content/runs/detect/train2/weights/best.pt' data='/content/drive/MyDrive/Dataset- -Conference/main_dataset.yaml'"
      ],
      "metadata": {
        "id": "AH4b_L_Qujy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0dd8a7-f6f9-4e8a-81d0-a255b54922e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n",
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3008573 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Dataset- -Conference/valid/labels.cache... 256 images, 0 backgrounds, 0 corrupt: 100% 256/256 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 16/16 [00:11<00:00,  1.38it/s]\n",
            "                   all        256        277      0.604        0.5      0.535      0.347\n",
            "   PEDESTRIAN CROSSING        256          9      0.669      0.778      0.768      0.469\n",
            "   speed limit 40 km/h        256         28       0.65      0.643       0.67      0.441\n",
            "   speed limit 80 km/h        256         26      0.587      0.329      0.466      0.296\n",
            "             Road Hump        256         19      0.835      0.474      0.605      0.382\n",
            "         No Overtaking        256         55      0.595      0.636      0.636       0.38\n",
            "        Side Road Left        256         26      0.669      0.731       0.74      0.506\n",
            "                School        256         28      0.782      0.714      0.776      0.519\n",
            "Sharp Bend To The Left        256         10       0.42        0.2      0.229      0.171\n",
            "       Side Road Right        256         15      0.479      0.667      0.726      0.473\n",
            "         Narrow Bridge        256         12      0.463     0.0772      0.188      0.117\n",
            "        no use of horn        256          8      0.452      0.375      0.414      0.327\n",
            "                U Turn        256         11       0.61       0.43      0.494      0.349\n",
            "            Crossroads        256         15      0.309      0.467      0.417        0.3\n",
            "   Speed Limit 60 km/h        256          6      0.532      0.763      0.619      0.343\n",
            "Sharp Bend To The Right        256          9          1       0.22      0.275      0.129\n",
            "Speed: 1.9ms preprocess, 4.5ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    }
  ]
}