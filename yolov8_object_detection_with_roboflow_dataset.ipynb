{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samin-Sadaf7/ObjectDetectiongwithYolo/blob/main/yolov8_object_detection_with_roboflow_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# YOLOv8 Object Detection on a Dataset\n",
        "\n",
        "---\n",
        "\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset)\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wuZtUMEiKWY)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "## ‚ö†Ô∏è Disclaimer\n",
        "\n",
        "YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **03.01.2024** with version **YOLOv8.0.196**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "## Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on how to train YOLOv8 Object Detection, concurrently.\n",
        "\n",
        "## Pro Tip: Use GPU Acceleration\n",
        "\n",
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
        "\n",
        "## Steps in this Tutorial\n",
        "\n",
        "In this tutorial, we are going to cover:\n",
        "\n",
        "- Before you start\n",
        "- Install YOLOv8\n",
        "- CLI Basics\n",
        "- Inference with Pre-trained COCO Model\n",
        "- Roboflow Universe\n",
        "- Preparing a custom dataset\n",
        "- Custom Training\n",
        "- Validate Custom Model\n",
        "- Inference with Custom Model\n",
        "\n",
        "**Let's begin!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "a707b725-2b5e-4227-8a9c-c1bbd9f411b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug 14 17:35:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "cb4fcc9d-f63d-40a1-a296-6f70cfc0b7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **03.01.2024** with version **YOLOv8.0.196**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "8e24bf54-00b4-48cd-afa8-c3998553060b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 33.6/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVvaIYEEPOty"
      },
      "outputs": [],
      "source": [
        "# Git clone method (for development)\n",
        "\n",
        "# %cd {HOME}\n",
        "# !git clone github.com/ultralytics/ultralytics\n",
        "# %cd {HOME}/ultralytics\n",
        "# !pip install -e .\n",
        "\n",
        "# from IPython import display\n",
        "# display.clear_output()\n",
        "\n",
        "# import ultralytics\n",
        "# ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LymRvd2MDINe",
        "outputId": "fe9233c0-8c4f-4fd3-f28d-4e9ef092ae59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33S7zlkQku0"
      },
      "source": [
        "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
        "\n",
        "```\n",
        "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
        "          classify       predict        yolov8n-cls.yaml  args...\n",
        "          segment        val            yolov8n-seg.yaml  args...\n",
        "                         export         yolov8n.pt        format=onnx  args...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### üíª CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaE1kLS8R4CV"
      },
      "source": [
        "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Training on Traffic Sign Detection Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfRdK5ZcLlMw",
        "outputId": "39d9f5cf-45f5-43fd-bc88-c856f44749eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWYmNmE1G6MM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "xml_folder = 'label'\n",
        "img_folder = 'images'\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(xml_folder, exist_ok=True)\n",
        "os.makedirs(img_folder, exist_ok=True)\n",
        "\n",
        "# Get a list of all XML files in the current directory\n",
        "xml_files = [file for file in os.listdir() if file.endswith('.xml')]\n",
        "\n",
        "# Get a list of all PNG files in the current directory\n",
        "png_files = [file for file in os.listdir() if file.endswith('.png')]\n",
        "\n",
        "# Move XML files to the 'label' folder\n",
        "for xml_file in xml_files:\n",
        "    shutil.move(xml_file, os.path.join(xml_folder, xml_file))\n",
        "\n",
        "# Move PNG files to the 'images' folder\n",
        "for png_file in png_files:\n",
        "    shutil.move(png_file, os.path.join(img_folder, png_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPcNxNgeJobQ"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Define the data\n",
        "data = {\n",
        "    'nc': 15,\n",
        "    'train': '/content/drive/MyDrive/Dataset- -Conference/train/',\n",
        "    'val': '/content/drive/MyDrive/Dataset- -Conference/val/',\n",
        "    'names': [\n",
        "        'SpeedLimit60kmh',\n",
        "        'School',\n",
        "        'PEDESTRIANCROSSING',\n",
        "        'SharpBendToTheLeft',\n",
        "        'UTurn',\n",
        "        'speedlimit80kmh',\n",
        "        'NoOvertaking',\n",
        "        'SharpBendToTheRight',\n",
        "        'SideRoadLeft',\n",
        "        'SideRoadRight',\n",
        "        'speedlimit40kmh',\n",
        "        'NarrowBridge',\n",
        "        'RoadHump',\n",
        "        'nouseofhorn',\n",
        "        'Crossroads'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Write the data to conference.yml\n",
        "with open('conference.yml', 'w') as yaml_file:\n",
        "    yaml.dump(data, yaml_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDIR8eS4Vqd1"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "\n",
        "# Class names\n",
        "class_names =[\n",
        "        'SpeedLimit60kmh',\n",
        "        'School',\n",
        "        'PEDESTRIANCROSSING',\n",
        "        'SharpBendToTheLeft',\n",
        "        'UTurn',\n",
        "        'speedlimit80kmh',\n",
        "        'NoOvertaking',\n",
        "        'SharpBendToTheRight',\n",
        "        'SideRoadLeft',\n",
        "        'SideRoadRight',\n",
        "        'speedlimit40kmh',\n",
        "        'NarrowBridge',\n",
        "        'RoadHump',\n",
        "        'nouseofhorn',\n",
        "        'Crossroads'\n",
        "    ]\n",
        "\n",
        "# Create class dictionary\n",
        "class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "def xml_to_yolo(xml_file, class_dict):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    image_size = root.find('size')\n",
        "    width = float(image_size.find('width').text)\n",
        "    height = float(image_size.find('height').text)\n",
        "\n",
        "    yolo_annotations = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text.strip().replace(' ', '').replace('/', '')  # Remove spaces and '/'\n",
        "        class_id = class_dict.get(class_name)\n",
        "        if class_id is None:\n",
        "            print(f\"Warning: Class '{class_name}' not found in class dictionary.\")\n",
        "            continue\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Calculate normalized coordinates\n",
        "        x_center = (xmin + xmax) / (2 * width)\n",
        "        y_center = (ymin + ymax) / (2 * height)\n",
        "        bbox_width = (xmax - xmin) / width\n",
        "        bbox_height = (ymax - ymin) / height\n",
        "\n",
        "        yolo_annotations.append(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\")\n",
        "\n",
        "    return yolo_annotations\n",
        "\n",
        "\n",
        "def convert_annotations(xml_dir, output_dir, class_dict):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for xml_file in os.listdir(xml_dir):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            img_id = os.path.splitext(xml_file)[0]\n",
        "            yolo_annotations = xml_to_yolo(os.path.join(xml_dir, xml_file), class_dict)\n",
        "            with open(os.path.join(output_dir, f\"{img_id}.txt\"), 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "# Paths\n",
        "xml_dir = '/content/drive/MyDrive/Dataset- -Conference/train/labels1'\n",
        "output_dir = '/content/drive/MyDrive/Dataset- -Conference/train/labels'\n",
        "\n",
        "# Convert annotations\n",
        "convert_annotations(xml_dir, output_dir, class_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulI-MZ0YfJ3o"
      },
      "outputs": [],
      "source": [
        "# train label Paths\n",
        "xml_dir = '/content/drive/MyDrive/Dataset- -Conference/train/labels1'\n",
        "output_dir = '/content/drive/MyDrive/Dataset- -Conference/train/labels'\n",
        "\n",
        "# Convert annotations\n",
        "convert_annotations(xml_dir, output_dir, class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90HvkLOafZEf"
      },
      "outputs": [],
      "source": [
        "# valid test Paths\n",
        "xml_dir = '/content/drive/MyDrive/Dataset- -Conference/val/labels1'\n",
        "output_dir = '/content/drive/MyDrive/Dataset- -Conference/val/labels'\n",
        "\n",
        "# Convert annotations\n",
        "convert_annotations(xml_dir, output_dir, class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO()  # build a new model from scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeV6EkvWWdUB",
        "outputId": "f8b5b3e5-bc36-4545-efa7-8d4d22760f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 21.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBqn-3uoFFEh",
        "outputId": "40afea0b-0610-43c6-b78c-8c3350c7b082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 332MB/s]\n",
            "New https://pypi.org/project/ultralytics/8.2.77 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/BD_Road_Sign_Dataset/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 95.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=28\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    756772  ultralytics.nn.modules.head.Detect           [28, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3016308 parameters, 3016292 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/BD_Road_Sign_Dataset/train/labels... 2556 images, 3 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2556/2556 [28:18<00:00,  1.50it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/BD_Road_Sign_Dataset/train/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:161: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/BD_Road_Sign_Dataset/valid/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:59<00:00,  1.28s/it]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/BD_Road_Sign_Dataset/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000313, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20      2.47G     0.8122      4.297      1.063         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:13<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.53s/it]\n",
            "                   all         46         49      0.373       0.39      0.281      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20      2.33G     0.7533      3.147      1.019         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:05<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.61it/s]\n",
            "                   all         46         49      0.526      0.444       0.48      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20      2.33G     0.7196      2.683      1.001         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:07<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.61it/s]\n",
            "                   all         46         49      0.641      0.537      0.632      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/20      2.34G     0.7006       2.35     0.9975         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:10<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.71it/s]\n",
            "                   all         46         49      0.838      0.533      0.662      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/20      2.33G     0.6681      2.062     0.9803         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:07<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.61it/s]\n",
            "                   all         46         49      0.466      0.676      0.676        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/20      2.33G     0.6356      1.816     0.9679         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:07<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.38it/s]\n",
            "                   all         46         49      0.555      0.753      0.768      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/20      2.34G     0.6258      1.621     0.9725         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:06<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.16it/s]\n",
            "                   all         46         49      0.822      0.619      0.775      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/20      2.34G     0.6043      1.446     0.9512         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:04<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.44it/s]\n",
            "                   all         46         49      0.773       0.75      0.788      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/20      2.34G     0.6028      1.345     0.9541         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:13<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s]\n",
            "                   all         46         49       0.69      0.785       0.83       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/20      2.34G     0.5841      1.267     0.9477         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:12<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.90it/s]\n",
            "                   all         46         49      0.739      0.799      0.824      0.739\n",
            "Closing dataloader mosaic\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:161: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/20      2.34G     0.5019      1.151     0.8892         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:13<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]\n",
            "                   all         46         49      0.781       0.83      0.883      0.786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/20      2.34G     0.4874      1.024     0.8856         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:03<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.72it/s]\n",
            "                   all         46         49      0.854       0.82      0.864      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/20      2.34G     0.4743     0.9225     0.8804         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:06<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.92it/s]\n",
            "                   all         46         49      0.893       0.89      0.924      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/20      2.34G     0.4659     0.8586     0.8716         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:03<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.82it/s]\n",
            "                   all         46         49      0.873      0.892      0.932      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/20      2.34G       0.46     0.8012     0.8779         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:04<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.73it/s]\n",
            "                   all         46         49      0.774      0.933      0.934      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/20      2.34G     0.4415     0.7481     0.8669         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:04<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.23it/s]\n",
            "                   all         46         49      0.868      0.931      0.937      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/20      2.34G     0.4326     0.7119     0.8696         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:01<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.95it/s]\n",
            "                   all         46         49      0.911      0.926      0.942      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/20      2.34G     0.4225     0.6876     0.8635         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:05<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.21it/s]\n",
            "                   all         46         49      0.838      0.903      0.941       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/20      2.34G     0.4117     0.6637     0.8518         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:02<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.47it/s]\n",
            "                   all         46         49      0.873      0.894      0.941      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/20      2.34G     0.4018     0.6336     0.8526         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [01:04<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.25it/s]\n",
            "                   all         46         49      0.869      0.918      0.949      0.876\n",
            "\n",
            "20 epochs completed in 0.385 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3011108 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.38it/s]\n",
            "                   all         46         49      0.874      0.894      0.941      0.881\n",
            "              Bus Stop         46          1      0.863          1      0.995      0.995\n",
            "      Crossroads Ahead         46          2      0.984          1      0.995      0.995\n",
            "               Go Left         46          2      0.915          1      0.995      0.947\n",
            "               Go Slow         46          1      0.863          1      0.995      0.895\n",
            "        Hospital Ahead         46          2      0.967        0.5      0.523      0.419\n",
            "             Left Turn         46          2      0.899          1      0.995      0.946\n",
            "   Narrow Bridge Ahead         46          1     0.0817      0.163      0.497      0.497\n",
            "Narrow Road on Left Ahead         46          2      0.904          1      0.995      0.995\n",
            "              No Horns         46          1      0.895          1      0.995      0.995\n",
            "         No-Overtaking         46          3      0.928          1      0.995      0.995\n",
            "   Rail Crossing Ahead         46          1      0.863          1      0.995      0.895\n",
            "            Right Turn         46          4      0.935          1      0.995      0.971\n",
            "          Road On Left         46          1      0.821          1      0.995      0.895\n",
            "         Road On Right         46          2          1      0.605      0.995      0.822\n",
            "          School Ahead         46          6      0.955          1      0.995      0.927\n",
            "   Speed Breaker Ahead         46          2      0.841        0.5      0.828      0.617\n",
            "     Speed Limit 20kmh         46          1      0.875          1      0.995      0.995\n",
            "     Speed Limit 40kmh         46          7       0.98          1      0.995      0.966\n",
            "     Speed Limit 60kmh         46          3      0.938          1      0.995      0.953\n",
            "                  Stop         46          1      0.866          1      0.995      0.895\n",
            " Street Crossing Ahead         46          4      0.972          1      0.995      0.874\n",
            "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "results = model.train(data='/content/drive/MyDrive/BD_Road_Sign_Dataset/data.yaml', epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PsvXzL_v4L_j",
        "outputId": "1cc2c360-3a6f-4c8c-f91c-f24d06b77769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Define paths\n",
        "import shutil\n",
        "source_folder = '/content/runs'\n",
        "destination_folder = '/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8'  # Path to the destination folder\n",
        "# Copy the folder and its contents to the destination\n",
        "shutil.copytree(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "AFJEcH9W989P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zlHLeiv5Jd8",
        "outputId": "50319a0a-2b48-4ec7-a318-95da5570117a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3011108 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/BD_Road_Sign_Dataset/valid/labels.cache... 46 images, 0 backgrounds, 0 corrupt: 100% 46/46 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.09s/it]\n",
            "                   all         46         49      0.873      0.894      0.941      0.879\n",
            "              Bus Stop         46          1      0.862          1      0.995      0.995\n",
            "      Crossroads Ahead         46          2      0.985          1      0.995      0.995\n",
            "               Go Left         46          2      0.915          1      0.995      0.947\n",
            "               Go Slow         46          1      0.862          1      0.995      0.895\n",
            "        Hospital Ahead         46          2      0.967        0.5      0.523      0.419\n",
            "             Left Turn         46          2      0.899          1      0.995      0.946\n",
            "   Narrow Bridge Ahead         46          1     0.0817      0.163      0.497      0.497\n",
            "Narrow Road on Left Ahead         46          2      0.903          1      0.995      0.995\n",
            "              No Horns         46          1      0.895          1      0.995      0.995\n",
            "         No-Overtaking         46          3      0.928          1      0.995      0.995\n",
            "   Rail Crossing Ahead         46          1      0.862          1      0.995      0.895\n",
            "            Right Turn         46          4      0.935          1      0.995      0.946\n",
            "          Road On Left         46          1       0.82          1      0.995      0.895\n",
            "         Road On Right         46          2          1      0.608      0.995      0.895\n",
            "          School Ahead         46          6      0.955          1      0.995      0.914\n",
            "   Speed Breaker Ahead         46          2       0.84        0.5      0.828      0.617\n",
            "     Speed Limit 20kmh         46          1      0.874          1      0.995      0.995\n",
            "     Speed Limit 40kmh         46          7       0.98          1      0.995      0.966\n",
            "     Speed Limit 60kmh         46          3      0.938          1      0.995      0.995\n",
            "                  Stop         46          1      0.865          1      0.995      0.796\n",
            " Street Crossing Ahead         46          4      0.972          1      0.995      0.874\n",
            "Speed: 4.0ms preprocess, 22.7ms inference, 0.0ms loss, 21.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Now you can run your YOLO command\n",
        "from ultralytics import YOLO\n",
        "!yolo task=detect mode=val model='/content/runs/detect/train/weights/best.pt' data=/content/drive/MyDrive/BD_Road_Sign_Dataset/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f43IPtZi6x2J",
        "outputId": "be523ba1-9baf-40ab-d1c3-dc3109a00c0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8/final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Define paths\n",
        "import shutil\n",
        "source_folder = '/content/runs/'\n",
        "destination_folder = '/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8/final'  # Path to the destination folder\n",
        "# Copy the folder and its contents to the destination\n",
        "shutil.copytree(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II87qmJ07kfp",
        "outputId": "49ddc2ef-7a3e-4866-c251-67b2bf040ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3011108 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/IMG_0026_PNG.rf.7c7f008ae721f06eb25688fb54beaddb.jpg: 640x640 1 Speed Limit 60kmh, 7.7ms\n",
            "image 2/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/IMG_0055_PNG.rf.8e2037142b302388508bada09715736b.jpg: 640x640 1 Road On Left, 7.5ms\n",
            "image 3/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/IMG_0061_PNG.rf.e1e5e8e560b21d3166faa6e9ba5196ed.jpg: 640x640 1 Right Turn, 7.5ms\n",
            "image 4/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-201056_jpg.rf.f338087bb3ced2ae099a8a0acf6d5252.jpg: 640x640 1 Go Slow, 7.5ms\n",
            "image 5/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-203139_jpg.rf.f63f5cdedc032633e6ef3f9fb10be401.jpg: 640x640 1 Filling Station Ahead, 7.5ms\n",
            "image 6/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-205440_jpg.rf.3d58f0bd7f84f1270ff9c7fe86cfab28.jpg: 640x640 1 Left Turn, 7.5ms\n",
            "image 7/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-205720_jpg.rf.fa3d9a8899f2ab4fbcc7c5ad037f3a2c.jpg: 640x640 1 No Horns, 8.1ms\n",
            "image 8/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-211255_jpg.rf.f2ddf1e25913a5f2590fec37fdb646d1.jpg: 640x640 1 Street Crossing Ahead, 8.7ms\n",
            "image 9/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-212213_jpg.rf.d415c4003570c43c669e52338b5a3d6d.jpg: 640x640 1 Road On Left, 8.1ms\n",
            "image 10/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-212237_jpg.rf.e9d078862c89441be2e786347368e539.jpg: 640x640 1 Crossroads Ahead, 14.2ms\n",
            "image 11/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-212636_jpg.rf.05d414b1ea31f426571d6c3417635a8b.jpg: 640x640 1 No-Overtaking, 15.2ms\n",
            "image 12/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-23-212706_jpg.rf.98f875d3f2a4fead4fb53b65d7423f8c.jpg: 640x640 1 No-Overtaking, 7.5ms\n",
            "image 13/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-190943_jpg.rf.e7596468633dd57a33535910b77f4ff6.jpg: 640x640 1 No-Overtaking, 7.5ms\n",
            "image 14/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-191815_jpg.rf.2172e2c0f973b08b94eb3da9fa0cc0e0.jpg: 640x640 1 Mosque Ahead, 7.5ms\n",
            "image 15/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-192457_jpg.rf.fdf68b0ab8eadad0ef698d12bc757623.jpg: 640x640 1 No-Overtaking, 7.6ms\n",
            "image 16/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-193026_jpg.rf.253609b70ba42814cbc6e60dd8096595.jpg: 640x640 1 Go Left, 7.5ms\n",
            "image 17/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-193035_jpg.rf.4fc419021b37c8eb59fae20ce2ca9b18.jpg: 640x640 1 Go Left, 7.5ms\n",
            "image 18/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-24-195614_jpg.rf.3c3689c95bd446ada9a7dc125afea7f5.jpg: 640x640 1 Bus Stop, 7.5ms\n",
            "image 19/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-225002_jpg.rf.3443a73e8e819e3b9ed4594570403ecf.jpg: 640x640 1 Mosque Ahead, 7.5ms\n",
            "image 20/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-225221_jpg.rf.93f3815f9b0d0caaf51fdb997ce85f61.jpg: 640x640 1 Mosque Ahead, 7.5ms\n",
            "image 21/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-225229_jpg.rf.ff89ca654c38b52b0098c87e46a68dae.jpg: 640x640 1 Mosque Ahead, 8.3ms\n",
            "image 22/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-231136_jpg.rf.2ffd1eeed35e32826885d0327c5d0bff.jpg: 640x640 1 Bus Stop, 7.5ms\n",
            "image 23/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-231621_jpg.rf.f88914b275e7f3a7020f38ab4ccf6228.jpg: 640x640 1 Left Turn, 7.5ms\n",
            "image 24/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-231630_jpg.rf.7df256ff3effba2d6ab5b5c42505f146.jpg: 640x640 1 Left Turn, 7.5ms\n",
            "image 25/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-231647_jpg.rf.2670c441d14697a089d9e82bcb2b4d8a.jpg: 640x640 1 Left Turn, 7.5ms\n",
            "image 26/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-25-232903_jpg.rf.29aa1c2c8cfcd0269d8fa1890816ad1e.jpg: 640x640 1 Road On Right, 7.5ms\n",
            "image 27/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-26-001748_jpg.rf.83f104e6fef11eaeda8ddbd8c8a329cd.jpg: 640x640 1 Bus Stop, 10.8ms\n",
            "image 28/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-26-001818_jpg.rf.562b38906e534e99fbb51b4b14142c44.jpg: 640x640 1 Bus Stop, 10.6ms\n",
            "image 29/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-26-002243_jpg.rf.143d07dea3508596a837428b5e56521d.jpg: 640x640 1 School Ahead, 10.1ms\n",
            "image 30/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-26-002400_jpg.rf.a3b61f2f253b134a0173bbe41990fe19.jpg: 640x640 1 School Ahead, 10.2ms\n",
            "image 31/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot-2023-08-26-002605_jpg.rf.f6a09dd8184c9f5b15d0f5894865bed7.jpg: 640x640 1 Bus Stop, 14.6ms\n",
            "image 32/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230812_135956_jpg.rf.e77f2ebdf7eaed96f185b6123af5bcd2.jpg: 640x640 1 Right Turn, 7.5ms\n",
            "image 33/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_081731_jpg.rf.aecf9a99a489af3fed8e99382667b0f0.jpg: 640x640 1 Street Crossing Ahead, 7.5ms\n",
            "image 34/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_082536_jpg.rf.a4da56fda323ce570cdbefabd797b47d.jpg: 640x640 1 Speed Limit 80kmh, 7.4ms\n",
            "image 35/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_083450_jpg.rf.9c5bfdb02024a97b0a69831a8568b986.jpg: 640x640 1 Left Turn, 7.5ms\n",
            "image 36/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_083811_jpg.rf.2d4dfbc2b1adfa2038cc6488209b2243.jpg: 640x640 1 Right Turn, 7.5ms\n",
            "image 37/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_220203_jpg.rf.98d28071976f643847e2fba6ca5bd5a0.jpg: 640x640 1 Speed Limit 40kmh, 8.1ms\n",
            "image 38/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_220732_jpg.rf.4479c0c41d00814550eec87c7b959caf.jpg: 640x640 1 Road On Right, 7.5ms\n",
            "image 39/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230825_221210_jpg.rf.6c3e1fbf2529567eb9e3106bd4a556d5.jpg: 640x640 1 Right Turn, 7.5ms\n",
            "image 40/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_002708_jpg.rf.4cc72f4f26f9a1bc79d8becb2f9befb4.jpg: 640x640 1 School Ahead, 7.5ms\n",
            "image 41/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_003152_jpg.rf.145a68ec8adef8d7d02f97b253404700.jpg: 640x640 1 Go Left, 7.5ms\n",
            "image 42/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_003210_jpg.rf.0753c747ac3c58ce16d21180084774f2.jpg: 640x640 1 Go Left, 7.5ms\n",
            "image 43/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_003700_jpg.rf.928f9fe238e11d93a1737edee7c629d8.jpg: 640x640 1 Narrow Road Ahead, 7.5ms\n",
            "image 44/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_004040_jpg.rf.37f7bbab87a58727c62b23b57529f0d7.jpg: 640x640 1 Speed Limit 60kmh, 7.5ms\n",
            "image 45/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_004207_jpg.rf.d7eca7430bd57e00cf43a7752b1eb08e.jpg: 640x640 1 Speed Limit 60kmh, 8.5ms\n",
            "image 46/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_004345_jpg.rf.52d9b4fa08893efa3eee7fa5afd435ef.jpg: 640x640 1 Speed Limit 60kmh, 7.5ms\n",
            "image 47/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_004810_jpg.rf.4f9dae2c01c0cd0eefc6718de8f5edb4.jpg: 640x640 1 Speed Limit 40kmh, 11.1ms\n",
            "image 48/48 /content/drive/MyDrive/BD_Road_Sign_Dataset/test/images/Screenshot_20230826_005051_jpg.rf.6b955aa40a26479b0305f9e3c8c50e62.jpg: 640x640 1 Speed Limit 40kmh, 12.8ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 13.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "# Run on test set for prediction\n",
        "!yolo task=detect mode=predict model='/content/runs/detect/train/weights/best.pt' conf=0.25 source='/content/drive/MyDrive/BD_Road_Sign_Dataset/test/images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7WUqc6O28j9y",
        "outputId": "f5ac4a54-5bed-4687-a263-2cf6ffb9c61d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8/test_final'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Define paths\n",
        "import shutil\n",
        "source_folder = '/content/runs'\n",
        "destination_folder = '/content/drive/MyDrive/BD_Road_Sign_Dataset/yolov8/test_final'  # Path to the destination folder\n",
        "# Copy the folder and its contents to the destination\n",
        "shutil.copytree(source_folder, destination_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}